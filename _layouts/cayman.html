<!DOCTYPE html>
<html lang="{{ site.lang | default: "en-US" }}">
  <head>
    <meta charset="UTF-8">
    
  {% seo %}
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="black">
    <meta name="apple-mobile-web-app-status-bar-style" content="white">
    <link rel="stylesheet" href="{{ '/assets/css/style.css?v=' | append: site.github.build_revision | relative_url }}">
    {% include head-custom.html %}
  
  <script src=
  "https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js">
  </script>
  <script src="./script.js"></script>
  <link rel="stylesheet" href="./styles.css">

  <style>
    * {
      box-sizing: border-box;
    }
    
    .column {
      float: left;
      width: 33.33%;
      padding: 5px;
    }
    
    /* Clearfix (clear floats) */
    .row::after {
      content: "";
      clear: both;
      display: table;
    }
  </style>

  <style>div {
    text-align:center;
    vertical-align: middle;
  }</style>
  </head>

  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">{{ page.title | default: site.title | default: site.github.repository_name }}</h1>
      <h2 class="project-tagline">{{ page.description | default: site.description | default: site.github.project_tagline }}</h2>
      {% if site.github.is_project_page %}
        <a href="https://github.com/epfl-ada/ada-2022-project-strauss" class="btn">Project github</a>
      {% endif %}
      {% if site.show_downloads %}
        <a href="https://aprakyk.github.io/ada-strauss-website/Homepage" class="btn">Home</a>
        <a href="https://aprakyk.github.io/ada-strauss-website/story" class="btn">Data story</a>
        <a href="https://aprakyk.github.io/ada-strauss-website/thanks" class="btn">Acknowledgment  & Credentials</a>
        <a href="https://aprakyk.github.io/ada-strauss-website/team" class="btn">Team</a>
      {% endif %}
    </header>

    <main id="content" class="main-content" role="main">

      <p align="center" style="color :rgb(170, 78, 46); " font-family: cursive;>
         <i> Once upon time, there was a wide and powerful website called Youtube. However, everything was not as perfect as it seemed : often, some 
          malicious people spread venomous comments...</i>
      </p>

      <h1>In the universe of Youtube</h1>
      <h2>Clustering</h2>

      <p align="center">
          <img width="500" src="https://blog.diegovalle.net/images/blogger_images/2.bp.blogspot.com_-vnzgFLAoZuE_VNgQ4jE_JnI_AAAAAAAAI60_YOjJurv4NMk_s1600_prd.png" >
      </p>
      
      <p align="center">
          <a href="https://blog.diegovalle.net/2015/02/the-most-partisan-first-names.html"><i>Is it me or is it hot in here?</i></a>
      </p>

      <p align="center">
        <i>TITLE</i>
      </p>

      <p>Our goal in this part is to compute how tight knit the extreme communities <b>Alt-lite</b>, <b>IDW</b> and <b>Alt-right</b> are. To this end, we’ll define 
        a graph where the nodes represent youtube channels (not necessarily associated to extreme communities) and edges represent their 
        influence on each other. We’ll then compute cluster coefficient to quantify the influence of the channels on each other.
      </p>
      
     <h3>Building a directed weighted graph</h3> 
      <p>To do so, we first defined a bipartite graph where one part represents users, the other part channels, and an edge is drawn between a 
        user and a channel if the user has commented on a video that was published by that channel.</p> 
        <p align="center">
          <img width="225" title="Bipartite graph for the authors and channels for the Youniverse dataset" src="assets/img/bipartite.png" >
        </p>

        <p align="center">
          <i>Bipartite graph for the authors and channels for the Youniverse dataset</i>>
        </p>
      <p>
        Then we collapsed the bipartite graph by only 
        keeping the nodes corresponding to channels and drawing an edge between two nodes if they were connected to the same user in the bipartite
         graph. Since we were interested in how influential channels are, we turned the undirected edges into double directed edges and associated
          each edge to a weight: the proportion of people who commented on one channel who also commented on the other channel. </p>
        <p align="center">
          <img width="400" title="Directed weighted graphic" src="assets/img/directed_graph.png" >
        </p>

        <p align="center">
          <i>Directed weighted graphic example</i>>
        </p>

        <p>
        This way we’re able to quantify influence while taking into account the fact that some channels have more subscribers than others: if 
        channel A is more influential than channel B the edge from B to A would have more weight than the weight from A to B. Now that we’ve 
        defined our graph, we’ll compute two clustering coefficients: their <a href="https://fr.wikipedia.org/wiki/PageRank"><b>page rank coefficient</b></a> (computed for a directed graph using 
        this <a href="https://www.sciencedirect.com/science/article/abs/pii/S096007791730509X?via%3Dihub">paper</a>) and their <a href="https://en.wikipedia.org/wiki/Clustering_coefficient"><b>local clustering coefficient</b></a> (computed for our graph seen as undirected). The point of computing both the page rank 
        and the local clustering coefficient is that it would allow us to compare how influential a channel is among all other channels versus 
        how influential it is among its network. 
        </p>
      
    <h3>How tight knit are our extreme communities?</h3>

      <p>We would expect the channels associated with extreme communities to have a higher local clustering coefficient than the average and a 
        lower page rank coefficient than the average (as we would expect them to be tight knit). We didn’t have time and the resource, and we underestimated 
        the size of our data to compute the local clustering coefficient but we did have time to compute the pagerank coefficient for the whole video set and for the time window restriction.</p>
      <p>We found an <b>average pagerank coefficient of ~1.10</b> for the community <b>Alt-right</b>, of <b>~4.85</b> for the community <b>Alt-lite</b> and of <b>3.20</b> for the 
        community <b>IDW</b> versus a pagerank coefficient of <b>0.48</b> for the <b>whole channel set</b>. </p>

        <p align="center">
        <table >

          <tr>
            <td rowspan="2">Average Pagerank coefficient</td>
            <td>Alt-lite</td>
            <td>Alt-right</td>
            <td>IDW</td>
            <td>whole video set</td>
          </tr>
          <tr>
            <td>~1.10</td>
  
            <td>~4.85</td>
            <td>~3.20</td>
            <td>~0.48</td>
          </tr>
        </table>
        </p>
        <p align="center">
          <i>Table of the average pagerank coefficient of the 4 considered communities</i>>
        </p>

      <p>The pagerank coefficient was much higher than we expected. Looking at the distribution of the video’s coefficients, we notice these are exceptionally high values located in the tail. This would mean that the channels from extreme communities have a lot of influence</p>
      <p>However, people change so maybe looking at a range of data over several years wouldn’t be representative of how clustered these communities are.</p>
    
    <h3>How do our clustering coefficients vary when we consider a shorter time window?</h3>
      
      <p>In a second time we’re only considering comments that have been made between 2018 and 2019 (we would expect if a clustered community is still alive that its members have commented during that time on all the community’s trending channels) and computing the pagerank cluster coefficients on this dataset. We get the following results: </p>

      <p align="center">
        <table class="center">

          <tr>
            <td rowspan="2">Pagerank coefficient</td>
            <td>Alt-lite</td>
            <td>Alt-right</td>
            <td>IDW</td>
            <td>whole video set</td>
          </tr>
          <tr>
            <td>6.12</td>

            <td>1.43</td>
            <td>4.01</td>
            <td>0.43</td>
          </tr>
        </table>
      </p>
      
      <p align="center">
        <i>Table of the pagerank coefficient of the 4 considered communities</i>
      </p>

      <p>We notice that these coefficients slightly decreased for the whole video set but considerably increased for the channels associated with extreme communities. This could mean that people don’t stay long in extreme communities but when they are part of it, they are very involved. </p>

    <h3>Discussion</h3>

      <p>When comparing the two clustering coefficients of extreme communities versus non-extreme communities, we didn’t take into consideration the number of the commentators on each channel. For a more rigorous analysis, we could do a matching based on this number between an extreme community channel and a random video and compute the averages on this set. 
       <br>
       When computing our clustering coefficients, we didn’t take into account edges that had a weight of less than 0.01 so there are a lot of channels associated with an extreme community that didn’t get taken into consideration.  
      </p>

    <h2>Quick summary</h2>

      <p>We defined a directed weighted graph using youtube channels as nodes and could only compute the (directed) pagerank clustering coefficient for each node. We found that the extreme communities had a considerably higher coefficient compared to the whole dataset and that gap difference only increased when we restricted our time window and only took data on a one year interval. This could be consistent with the hypothesis that young people are attracted by far right content and get involved a lot in these communities but hopefully only during a short period of time (not on a long term basis). </p>


    <h2>Toxicity</h2>

      <p align="center">
        <img width="500" src="assets/img/toxic_behaviour.png" >
      </p>
      <p align="center">
        <i>TITLE ??</i> <a href="https://www.pinterest.fr/pin/551761391849970879/">Source</a>
      </p>

      
      <h3>Why do we focus on extreme communities? </h3>
      <p>Some extreme communities are well known for making toxic comments. Taking Trump for example:</p>
      <p align="center">
        <img width="500" src="assets/img/trump.png" >
      </p>
      <p align="center">
        <i>Tweet of Donald Trump on <a href="https://twitter.com/realDonaldTrump/status/332308211321425920">Twitter</a> on the 9th of May 2013</i>
      </p>
      
      
      
      <p>But how toxic is that tweet? Thankfully, we’re using a Machine Learning model called 
        <a href="https://github.com/unitaryai/detoxify">Detoxify</a>
         to compute how toxic a sentence is and how severe-toxic, obscene, threatening, sexually explicit, 
         identity attacking  and threatening it is. It rates it on a scale from 0 to 1 (0 not at all, 1 very). <br>
         To get an idea, a comment is considered to have a toxic score of 1 if if it is a very <i>‘hateful, 
          aggressive, or disrespectful that is very likely to make you leave a discussion or give up on sharing 
          your perspective’</i>. <br>
        For example Trump’s tweet had a score of :
        </p>
        <p align="center">
        <table class="tb" id="members">
          <tr>
            <th>Toxicity</th>
            <th>Severe toxicity</th>
            <th>Obscene</th>
            <th>Identity attack</th>
            <th>Insult</th>
            <th>Threat</th>
            <th>Sexual explicit</th>
          </tr>
          <tr>
            <th>0.994145</th>
            <th>0.000296</th>
            <th>0.004636</th>
            <th>0.005744</th>
            <th>0.988292</th>
            <th>0.000275</th>
            <th>0.000622</th>
          </tr>
        </table>
      </p>

      <p align="center">
        <i>Toxicity categories of Trump's tweet</i>
      </p>
        
        <p>It has a toxicity of ~0.994 and is very insulting (insult~0.988). <br>
        To get a better idea of what toxicity score is associated with what type of sentence, we're introducing the monkey scale:</p>
      
          <div class="chartMenu">
          </div>
          <div class="chartCard">
            <div class="chartBox">
              <canvas id="myChart"></canvas>
            </div>
          </div>
          <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/chart.js"></script>
          <script>
          // setup 
          const data = {
            labels: ['The monkey makes jokes', 'The mean monkey makes means jokes about means', 'The annoying monkey makes annoying jokes about means',
      'The vile monkey makes vile jokes about means', 'The malevolent monkey makes malevolent jokes about means', 
      'The nasty monkey makes nasty jokes about means', 'The despicable monkey makes despicable jokes about means', 
      'The bastard monkey makes bastard jokes about means'],
            datasets: [{
              label: 'Toxicity',
              data: [0.080424, 0.158876, 0.197954, 0.319232, 0.462587, 0.615834, 0.707401, 0.995640],
              backgroundColor: ['rgba(255, 26, 104, 0.2)',],
              borderColor: ['rgba(255, 26, 104, 1)',],
              borderWidth: 1
            }]
          };
          // config 
          const config = {
            type: 'bar',

            data,

            options: {
              scales: {
                  y: {
                    title: {
                      display: true,
                      text: 'Toxicity '
                    }
                  }
              },
              plugins : {
                legend : {
                  display : false
                },
              title: {
                display: true,
                text: 'Toxicity of the monkey scale'
                 }
              }
            }
          };
          
          // render init block
          const myChart = new Chart(
            document.getElementById('myChart'),
            config
          );
      
      </script>

      <p>Therefore we wondered if being toxic was one of the characteristic features of extreme communities. 
        Just as in the study <a href="https://dlab.epfl.ch/people/west/pub/HortaRibeiro-Ottoni-West-Almeida-Meira_FAT-20.pdf">“Auditing Radicalization Pathways on Youtube”</a>
        , by Ribeiro et al. (2020), 
        we decided to study the extreme communities <b>‘Alt-right’</b>,<b>‘Alt-lite</b> and <b>‘Intellectual Dark Web’</b>  
        aka I.D.W and use medias as our control group. <br>
        And hopefully twitter isn't the only place where you can be toxic, there is also the </p>
        <p align="center" style="color :rgb(255,163,132); ">
          Wonderful &#10024 <i>Comment section</i> &#10024 of youtube videos.
        </p>

      <h4>Key words</h4>

      <p>In this section, we'll use the terms :</p>
      <ul>
        <li> <b>toxic category</b> :  refers to the term toxicity or <i>severe_toxicity</i>, <i>obscene</i>, <i>identity_attack</i>…</li>
        <li> <b> toxic score array of a comment</b> :  its array output by <a href="https://github.com/unitaryai/detoxify">Detoxify</a> through all toxic categories. 
        </li>
        <li> <b>toxic category score</b> :  the value output by <a href="https://github.com/unitaryai/detoxify">Detoxify</a> for this toxic category </li>
        <li> <b>groups</b> :  refers to the 3 extreme communities <i>Alt-lite</i>, <i>Alt-right</i>, <i>IDW</i> and the control group
        </li>
      </ul>  

      <p>To study how toxic the comment section associated with a video is, we computed the <i>toxic_score_array</i>
      of each comment on that video and took their mean category wise. This way, 
      we defined the <i>toxic_score_array</i> of a video. Then we wondered how toxic the comment section of a video 
      associated with an extreme community is . </p>

      <h3>How does the toxic score array of a video associated with an extreme community compare to the one of a video associated with a media? </h3>
      
      <p>When we superimpose the distribution of a toxic category score in an extreme community with 
        the one in the control group, the one associated with the extreme community does seem to have a 
        higher score than the control group. Although on a general basis this score is small. Indeed, for 
        the toxic category <b>‘toxicity’</b> we see that in the extreme communities, the proportion of videos 
        having a high toxicity score is higher than the one of the control group. <br>
        But this toxicity is small as they all reach their peak around 0.2 (on the monkey scale, 
        it would be saying <i>“the annoying monkey made annoying jokes about means”</i>). </p>

      <div id="identity_attack"><center><iframe src="assets/graph/Histograms/final.html" height = "500", 
        width = "1000" frameBorder="0"> </iframe></center></div>
    

      <p>For the other toxic categories, we notice that the toxic category score distribution has a 
        larger proportion of videos associated with higher scores for the toxic categories <b>obscene</b>, 
        <b>identity_attack</b> and <b>insult</b>. From a first glance, it looks like the <b>Alt-right</b> might generate less 
        toxic comments out of the three extreme communities. 
        <br><br>
        Although they do not generate so much toxic behavior, there might be a trend where the most popular 
        videos (that we define as being the most watched) are also the ones generating the most toxic 
        behaviors. Meaning that although the community might not generate much toxicity, people might go 
        all out on the most popular videos. 
        </p>
      <h3>Is the popularity of a video correlated to its toxicity (or to any other toxic category)?</h3>

      <p>To check if there is a correlation, we plotted a scatter plot of each toxic category score and the 
        view count associated with the video. We also computed the correlation coefficient between the two 
        using Pearson’s (for linear correlation), Spearman’s (for monotonic correlation) and Kendall Tau’s 
        (for class correlation) correlation coefficient and their associated p-values. </p>
      
        <label for="hex-select"><b>Choose a toxic category</b></label>
        <select name="hex" id="hex-select">
            <option value="">Identity attack</option>
            <option value="insult">Insult</option>
            <option value="obscene">Obscene</option>
            <option value="severe">Severe toxicity</option>
            <option value="sexual">Sexual explicit</option>
            <option value="threat">Threat</option>
            <option value="toxicity">Toxicity</option>
        </select>
        
        <img id="graphique-1" src="assets/img/hex_plots_png/identity-attack.png"/>
        
        <script>
            const selectEl = document.getElementById("hex-select");
            selectEl.addEventListener("change", (ev) => {
            switch (selectEl.value) {
                case "insult":
                document.getElementById("graphique-1").src = "assets/img/hex_plots_png/insult.png";
                break;
                case "obscene":
                document.getElementById("graphique-1").src = "assets/img/hex_plots_png/obcene.png";
                break;
                case "severe":
                document.getElementById("graphique-1").src = "assets/img/hex_plots_png/severe-toxicity.png";
                break;
                case "sexual":
                document.getElementById("graphique-1").src = "assets/img/hex_plots_png/sexual-explicit.png";
                break;
                case "threat":
                document.getElementById("graphique-1").src = "assets/img/hex_plots_png/threat.png";
                break;
                case "toxicity":
                document.getElementById("graphique-1").src = "assets/img/hex_plots_png/toxicity.png";
                break;
                default:
                document.getElementById("graphique-1").src="assets/img/hex_plots_png/identity-attack.png";
                break;
            }
            })
        </script>

      <p align="center">
        <i>Scatter plot of the toxic category score and the view count associated with the videos.</i>
      </p>

      <p>
        For the toxicity categories of the channels of the four considered communities, we only take the correlation coefficient if the p-value is inferior to 0.05  
      </p>
      <table >
          <td style="text-align: center" colspan="7">Alt lite</td>
          <tr>
            <th>Toxicity</th>
            <th>Severe toxicity</th>
            <th>Obscene</th>
            <th>Identity attack</th>
            <th>Insult</th>
            <th>Threat</th>
            <th>Sexual explicit</th>
          </tr>
          <tr>
            <th>Spearman 0.285</th>
            <th>Spearman 0.512</th>
            <th>Spearman 0.415</th>
            <th>Spearman 0.358</th>
            <th>Spearman 0.287</th>
            <th>Spearman 0.489</th>
            <th>Spearman 0.489</th>
          </tr>
      </table>

      <p align="center">
        <i>Toxicity categories of the channels for <b>Alt lite</b></i>
      </p>

      <table >
          <td style="text-align: center" colspan="7">ALt right</td>
          <tr>
            <th>Toxicity</th>
            <th>Severe toxicity</th>
            <th>Obscene</th>
            <th>Identity attack</th>
            <th>Insult</th>
            <th>Threat</th>
            <th>Sexual explicit</th>
          </tr>
          <tr>
            <th>Spearman  0.204</th>
            <th>Spearman  0.435</th>
            <th>Spearman  0.327</th>
            <th>Spearman  0.306</th>
            <th>Kendall   0.169</th>
            <th>Spearman  0.455</th>
            <th>Spearman  0.422</th>
          </tr>
      </table>

      <p align="center">
        <i>Toxicity categories of the channels for <b>Alt right</b></i>
      </p>

      <table >
          <td style="text-align: center" colspan="7">Intellectual Dark Web</td>
          <tr>
            <th>Toxicity</th>
            <th>Severe toxicity</th>
            <th>Obscene</th>
            <th>Identity attack</th>
            <th>Insult</th>
            <th>Threat</th>
            <th>Sexual explicit</th>
          </tr>
          <tr>
            <th>Spearman 0.272</th>
            <th>Spearman 0.504</th>
            <th>Spearman 0.413</th>
            <th>Spearman 0.384</th>
            <th>Spearman 0.263</th>
            <th>Spearman 0.589</th>
            <th>Spearman 0.506</th>
          </tr>
      </table>

      <p align="center">
        <i>Toxicity categories of the channels for <b>Intellectual Dark Web</b></i>
      </p>

      <table >
          <td style="text-align: center" colspan="7">Control</td>
          <tr>
            <th>Toxicity</th>
            <th>Severe toxicity</th>
            <th>Obscene</th>
            <th>Identity attack</th>
            <th>Insult</th>
            <th>Threat</th>
            <th>Sexual explicit</th>
          </tr>
          <tr>
            <th>Spearman 0.173</th>
            <th>Spearman 0.373</th>
            <th>Spearman 0.339</th>
            <th>Spearman 0.238</th>
            <th>Spearman 0.242</th>
            <th>Spearman 0.352</th>
            <th>Spearman 0.406</th>
          </tr>
      </table>

      <p align="center">
        <i>Toxicity categories of the channels for <b>Control</b></i>
      </p>

      <p>It turns out that there is either no correlation (among correlation coefficients associated with 
        a p-values less than 0.05, we only have a correlation coefficient of 0.1) or a correlation similar 
        to the one in the control group (ex: correlation of 0.4 between <i>sexual_explicite</i> score and the view 
        count for all 4 groups considered) . However, looking at the scatter plots, we notice that often 
        there is a very large proportion of videos in one exact spot, especially the one corresponding to 
        videos that have a little view count and a little toxic category score. So what would happen if we 
        only looked at the top 25 most seen videos &#128064? We’re computing again the scatter plots and 
        the various correlation coefficients.
      </p>

      <div id="identity_attack"><center><iframe src="assets/graph/Scatter_views_videos/final.html" height = "500", 
        width = "1000" frameBorder="0"> </iframe></center></div>

        <p>
          For the toxicity categories of the videos of the four considered communities, we only take the correlation coefficient if the p-value is inferior to 0.05  
        </p>

      <table >
          <td style="text-align: center" colspan="7">Alt lite</td>
          <tr>
            <th>Toxicity</th>
            <th>Severe toxicity</th>
            <th>Obscene</th>
            <th>Identity attack</th>
            <th>Insult</th>
            <th>Threat</th>
            <th>Sexual explicit</th>
          </tr>
          <tr>
            <th>Kendall  -0.193</th>
            <th>Kendall  -0.127</th>
            <th>Pearson  -0.056</th>
            <th> - </th>
            <th>Pearson  -0.181</th>
            <th>Pearson  -0.147</th>
            <th>Spearman -0.152</th>
          </tr>
      </table>

      <p align="center">
        <i>Toxicity categories of the videos for <b>Alt lite</b></i>
      </p>

      <table >
          <td style="text-align: center" colspan="7">ALt right</td>
          <tr>
            <th>Toxicity</th>
            <th>Severe toxicity</th>
            <th>Obscene</th>
            <th>Identity attack</th>
            <th>Insult</th>
            <th>Threat</th>
            <th>Sexual explicit</th>
          </tr>
          <tr>
            <th>Pearson   0.403</th>
            <th>Pearson   0.658</th>
            <th>Pearson   0.555</th>
            <th> - </th>
            <th>Pearson   0.457</th>
            <th>Pearson   0.47</th>
            <th>Pearson   0.7</th>
          </tr>
      </table>

      <p align="center">
        <i>Toxicity categories of the videos for <b>Alt right</b></i>
      </p>

      <table >
          <td style="text-align: center" colspan="7">Intellectual Dark Web</td>
          <tr>
            <th>Toxicity</th>
            <th>Severe toxicity</th>
            <th>Obscene</th>
            <th>Identity attack</th>
            <th>Insult</th>
            <th>Threat</th>
            <th>Sexual explicit</th>
          </tr>
          <tr>
            <th>Spearman 0.548</th>
            <th>Spearman 0.587</th>
            <th>Spearman 0.574</th>
            <th> - </th>
            <th>Spearman 0.641</th>
            <th>Spearman 0.206</th>
            <th>Spearman 0.576</th>
          </tr>
      </table>

      <p align="center">
        <i>Toxicity categories of the videos for <b>Intellectual Dark Web</b></i>
      </p>

      <table >
          <td style="text-align: center" colspan="7">Control</td>
          <tr>
            <th>Toxicity</th>
            <th>Severe toxicity</th>
            <th>Obscene</th>
            <th>Identity attack</th>
            <th>Insult</th>
            <th>Threat</th>
            <th>Sexual explicit</th>
          </tr>
          <tr>
            <th>Kendal tau  -0.133</th>
            <th> - </th>
            <th>Pearson     -0.158</th>
            <th>Kendal tau  -0.133</th>
            <th>Kendal tau  -0.147</th>
            <th>Pearson     -0.168</th>
            <th> - </th>
          </tr>
      </table>

      <p align="center">
        <i>Toxicity categories of the videos for <b>Control</b></i>
      </p>

      <p>
        Videos in <b>Alt right</b> and <b>IDW</b> have medium correlation coefficients between their view count and their 
        toxicity (Alt right has a Pearson’s correlation coefficient of 0.4 and IDW has a Spearman correlation 
        coefficient of 0.5 and both have associated p-value less than 0.05) and Alt-right and IDW also have a 
        higher than 0.4 correlation and p inferior to 0.05 for the toxic categories <i>sexual explicit</i> 
        comments, <i>threat</i>, 
        <i>insult</i>, <i>obscene</i> and <i>severe toxicity</i>. 
        <br><br>
        Now we can ask ourselves if that trend is only associated with a few videos and is not a channel 
        trend.
      </p>


      <h3>Is the popularity of a channel correlated to its toxicity  (or to any other toxic category)?</h3> 
      
      <p>Again we computed the scatter plots and the correlation coefficients : </p>

      <div id="identity_attack"><center><iframe src="assets/graph/Scatter_views_channels/final.html" height = "500", 
        width = "1000" frameBorder="0"> </iframe></center></div>

      <p>In this case, we noticed that all numbers and behavior coincide with the one of the control group 
        so it is not related to them being extreme communities. 
        <br><br>
        We have noticed that these extreme communities are more toxic than the control group media. 
        But has it always been the case or is there a trend where comments on youtube videos are becoming 
        more and more toxic? Already in 2018, Forbes published an article about how social media is becoming 
        too toxic. 
      </p>

      
      <p align="center">
        <img width="650" src="assets/img/ford.png" >
      </p>
      <p align="center">
        <a href="https://www.forbes.com/sites/kalevleetaru/2018/07/19/is-social-media-becoming-too-toxic/">Is social media becoming too toxic ?</a>
      </p>

      <p>This lead us to the following question : </p>
      <p align="center" style="color :rgb(11, 84, 240); ">
        <i>How have the different toxic category scores evolved through time?</i> &#129488
      </p>

      <h3>How have the different toxic category scores evolved through time?</h3>

      <p>By studying data between January 2014 and April 2019, we observe the monthly evolution of the 
        different toxic categories, among the 4 different groups. <br> 
        We first compared them to each other: 
        </p>

        <div id="identity_attack"><center><iframe src="assets/graph/Each_cat_tox/final.html" height = "500", 
          width = "1000" frameBorder="0"> </iframe></center></div>
          
      <p>As before, the subcategories <i>‘severe toxicity’</i>, <i>‘threat’</i> and <i>‘sexual explicit’</i> 
         have a very small scale throughout the time so their effect is negligible for each group. Furthermore, 
        concerning the other toxic categories, the toxic category scores associated with the <b>Alt-lite</b>  channel 
        are generally above the control group, though this is only a difference of max 0.05 point. The 
        <b>alt-right</b> and <b>IDW</b> communities have usually the same or greater score compared to the control 
        group. However, the differences are not noticeably high. <br><br>

        We have seen previously that group-wise, some toxic category scores tend to be higher than others, 
        we’re computing if it has always been the case. 
        </p>

        <div id="identity_attack"><center><iframe src="assets/graph/Each_chan_cat/final.html" height = "500", 
          width = "1000" frameBorder="0"> </iframe></center></div>     

      <p>On the graphs, we see that three toxic categories stand out: <i>toxicity</i>, <i>insult</i> and 
        <i>obscene</i>. 
        The fact that toxicity stands out makes sense as all the other toxic categories are defined as 
        ‘sub toxicities’ so it makes sense that they have lower scores. However, the fact that among toxic 
        comments a lot of them are insults or obscene is interesting. <br><br>

        Concerning the <b>Alt-lite</b> community, there is a small constant increase of the three main toxic 
        categories (mentioned above) until 2018, where a drop is observed (for a hypothesis on this, see
        discussion a.). After that, the values are quite stable. <br><br>
        Moreover, a steep increase is observed mid 2016 in <i>‘toxicity’</i>, <i>‘insult’</i> and <i>‘obscene’</i>  
        in the <b>Alt-right</b>
         community’s comments (for a hypothesis, see discussion b. ????????). We also see a peak in the 
        first quarter of 2018, however no political events seem to coincide with it.
        <br><br>
        We saw previously that the 25 most viewed videos per group have a stronger correlation with 
        each toxic category score than when we considered all the group’s videos. We’re computing how it 
        reflects in numbers throughout time.
        </p>

        <div id="identity_attack"><center><iframe src="assets/graph/Top25_tox/final.html" height = "500", 
          width = "1000" frameBorder="0"> </iframe></center></div>  
          
        <div id="identity_attack"><center><iframe src="assets/graph/Top25_chan/final.html" height = "500", 
          width = "1000" frameBorder="0"> </iframe></center></div>  

    <p>The top 25 videos of the month usually have the same or a noticeably higher mean than the monthly overall mean of their corresponding category.
       This is most detectable in the <b>Alt-lite</b> community. However, the reverse 
      happens in the control group. Indeed, after mid 2015, the most viewed videos are less toxic than the 
      mean of all the videos. <br> 
      Moreover, the absolute difference of toxicity in between the top 25 videos of <b>Alt-lite</b> and the control 
      group is bigger than 0.1, which is an important difference. This difference can also be observed in 
      other toxic categories, like <i>‘severe toxicity’</i>, <i>‘obscene’</i> , and <i>‘insult’</i>. The same way 
      among extreme 
      communities, <b>Alt-lite</b> is the one for which the difference between the toxic category score of the top 
      25 and the entire set of videos is the largest. <br>
      On a general basis, starting mid 2015, we observe a really different behavior between the control group 
      and the extreme communities. 
      </p>
    
    <h3>Discussion</h3>

    <p>We could look into the relationship between a video content and toxicity category score of the 
      associated comment section. By applying <a href="https://github.com/unitaryai/detoxify">Detoxify</a> on the caption of the comments we could study if 
      there is a correlation between the toxic category score of the caption of a video and the toxic 
      category score of its comment section. <br>
      Do notice that the machine learning model <a href="https://github.com/unitaryai/detoxify">Detoxify</a> has a lot of limits even the unbiased version. 
      E.g the formulation of a sentence can make the toxicity vary a lot: <i>'I am at the zoo and I see a 
        black monkey'</i> has a toxicity of 0.19 and <i>'I saw a black monkey at the zoo'</i> has a toxicity of 0.06. 
      (in [dataframe in toxic_example.ipynb] of the github of the Strauss project) <br>
      The same way, a comment is considered obscene if you use a swear word even in a positive way. For example the sentence <i>“that was fucking brilliant”</i> has an obscene score of ~0.95.
      </p>

    <p align="center">
    <table class="tb" id="members">
      <tr>
        <th>Toxicity</th>
        <th>Severe toxicity</th>
        <th>Obscene</th>
        <th>Identity attack</th>
        <th>Insult</th>
        <th>Threat</th>
        <th>Sexual explicit</th>
      </tr>
      <tr>
        <th>0.942965</th>
        <th>0.015987</th>
        <th>0.953825</th>
        <th>0.002574</th>
        <th>0.089621</th>
        <th>0.000974</th>
        <th>0.026361</th>
      </tr>
    </table> 
    </p>

    <p align="center">
      <i>Toxicity categories of the associated comment section</i>
    </p>

    <p>This raises the questions: 
      <p align="center" style="color :rgb(187, 11, 240); ">
        Can using a swear word hurt someone’s sensibility? Are swear words toxic? 
        <p align="right" style="color :rgb(207, 139, 209); "> 
        Any mom would obviously say yes....</p>
    
    <p>In further research, we could try to connect the variations in the toxic category scores to 
      major events. For example for a. =INTRALINK a hypothesis to explain why the values have dropped is the <b><i>#Metoo</i></b> 
      movement, starting in 2017 as a way to draw attention on the magnitude against sexual abuse and 
      harassment. For b. =INTRALINK it coincides with the election of Donald Trump in the United States. Indeed, in June 
      2015, he announced that he would be a candidate in the U.S. presidential election of 2016. In November 
      2016, he won the election. Also, following the Russian interference in the 2016 U.S. elections, 
      YouTube didn't initiate any moderation. <br> <br>

      In our project we only computed the correlation and didn’t conduct a causality study so this could 
      be ground for further research. 
      </p>
    
    <h2>Quick summary</h2>
    <p>Overall on average, videos associated with extreme communities have a higher toxic category score 
      than the ones associated with the control group but still have a relatively small score (around 0.2). 
      When looking at the evolution of the toxicity category scores through time per group, we find again 
      that the absolute differences seem negligible. We could assume some hypotheses about the reasons for 
      certain decreases and increases but, the toxicity levels did not seem abnormal.<br><br>
      When restricting ourselves to the 25 most seen videos and computing the correlation between the view 
      count and the toxic category scores, we get correlation scores as high as 0.6 for the extreme 
      communities Alt-right and IDW. However, when looking at the toxic category scores of the top 25 videos 
      per month per group, the most important score difference between the top 25 of the control group and 
      the top 25 of an extreme community is reached for Alt-lite with a score difference of more than 0.1 for 
      the toxicity. Moreover Alt-lite also has the highest toxic category scores difference between its top 
      25 videos and its whole video set. This difference could also be observed in other subcategories of 
      toxicity. This is really interesting as it means that although the top 25 videos of Alt-lite are the 
      ones generating the most toxic behaviors, it doesn’t seem like generating toxic behavior is something 
      specific to its most popular videos. On the opposite, for the Alt-right and IDW videos, they generate 
      less toxic behavior but there is a higher tendency that it would be something specific to popular 
      videos.<br> <br>
      In further research, for more precision we would need to investigate all the edge cases of the machine 
      learning algorithm <a href="https://github.com/unitaryai/detoxify">Detoxify</a>. Indeed, the scores become abnormally high when a certain biased vocabulary 
      is used, or when a sensitive couple of words is written together.
      </p>
    
    <h1>Conclusion</h1>


</html>
